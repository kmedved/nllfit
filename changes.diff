diff --git a/CHANGELOG.md b/CHANGELOG.md
index 3bd6768..1d6ba17 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,5 +1,34 @@
 # Changelog
 
+## 0.2.0 - 2026-02-07
+
+### Breaking Changes
+- `TwoStageHeteroscedasticLightGBM`: replaced `calibrate: bool` parameter with
+  `calibration_method: str` accepting `"none"`, `"holdout"`, `"oof"`, or `"train"`.
+  The old `calibrate` parameter still works but emits a `FutureWarning` and will
+  be removed in v0.3.0.
+- Default changed from `calibrate=True, calibration_fraction=0.0` (which did train
+  calibration) to `calibration_method="oof"` (OOF calibration, no data loss).
+- Default `n_iterations` changed from 1 to 2.
+- Default `oof_residuals_reuse` changed from False to True.
+
+### Added
+- `calibration_method="oof"`: calibrates variance scale using out-of-fold mean
+  predictions. No held-out data required, no in-sample bias. Recommended default.
+- `oof_mean_predictions()` in `hetero_nll.oof`: computes OOF mean predictions
+  (reuses same OOF splitter infrastructure).
+- `calibration_method="train"` emits a `UserWarning` about systematic variance
+  shrinkage with flexible models.
+- New tests: `test_calibration_method_oof`, `test_calibration_method_holdout`,
+  `test_calibration_method_train_warns`, `test_calibration_method_none`,
+  `test_calibration_method_invalid_raises`, `test_deprecated_calibrate_param_warns`,
+  `test_two_iter_oof_cal_improves_nll`, `test_explicit_cal_data_overrides`.
+
+### Fixed
+- Train calibration (calibrating on in-sample residuals) was producing scale << 1
+  with flexible mean models, causing severe variance shrinkage and undercoverage.
+  This is now deprecated in favor of OOF calibration.
+
 ## 0.1.0 - 2026-02-07
 - Initial release: two-stage heteroscedastic regression for GLUM and LightGBM.
 - OOF residuals for LightGBM variance stage.
diff --git a/README.md b/README.md
index bbade9d..bcbb8cd 100644
--- a/README.md
+++ b/README.md
@@ -51,8 +51,7 @@ X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_
 m = TwoStageHeteroscedasticLightGBM(
     n_oof_folds=5,
     variance_mode="auto",
-    calibrate=True,
-    calibration_fraction=0.2,
+    calibration_method="oof",  # "oof" | "holdout" | "none"
 )
 m.fit(X_train, y_train)
 
diff --git a/examples/basic_usage.py b/examples/basic_usage.py
index 5746955..9ac94ea 100644
--- a/examples/basic_usage.py
+++ b/examples/basic_usage.py
@@ -27,9 +27,9 @@ def main():
 
     model = TwoStageHeteroscedasticLightGBM(
         n_oof_folds=5,
+        n_iterations=2,
         variance_mode="auto",
-        calibrate=True,
-        calibration_fraction=0.2,
+        calibration_method="oof",
         time_col=None,
     )
     model.fit(X_train, y_train)
diff --git a/hetero_nll/_version.py b/hetero_nll/_version.py
index 3dc1f76..d3ec452 100644
--- a/hetero_nll/_version.py
+++ b/hetero_nll/_version.py
@@ -1 +1 @@
-__version__ = "0.1.0"
+__version__ = "0.2.0"
diff --git a/hetero_nll/estimators/lightgbm.py b/hetero_nll/estimators/lightgbm.py
index 83f1da7..f47701c 100644
--- a/hetero_nll/estimators/lightgbm.py
+++ b/hetero_nll/estimators/lightgbm.py
@@ -1,7 +1,8 @@
 from __future__ import annotations
 
+import warnings
 from dataclasses import dataclass
-from typing import Any, Dict, Optional, Tuple
+from typing import Any, Dict, Literal, Optional, Tuple
 
 import numpy as np
 
@@ -11,7 +12,7 @@ except Exception:  # pragma: no cover
     pd = None  # type: ignore
 
 from ..calibration import apply_variance_calibration, fit_variance_scale
-from ..oof import choose_oof_splitter, oof_squared_residuals
+from ..oof import choose_oof_splitter, oof_mean_predictions, oof_squared_residuals
 from ..splitting import TimeInfo, calibration_split, infer_time, time_sort
 from ..types import HeteroscedasticPrediction, VarianceCalibration
 from .base import HeteroscedasticRegressor, ArrayLike
@@ -52,13 +53,30 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
         according to variance_mode.
     variance_mode:
         "auto" | "gamma" | "log"
+    n_iterations:
+        Number of mean/variance alternating iterations. 2 is recommended: the
+        second iteration reweights the mean model by inverse predicted variance.
     n_oof_folds:
         If >1, use OOF residuals. If <=1, uses in-sample residuals (not recommended).
     oof_residuals_reuse:
         If True and n_iterations>1, compute OOF residuals once (based on the first
-        iteration's mean weights) and reuse for later iterations.
+        iteration's mean weights) and reuse for later iterations. Faster but approximate.
+    calibration_method:
+        How to calibrate the variance scale after fitting:
+          - "oof" (default): Calibrate using OOF mean predictions on the training
+            set. No data is held out, no in-sample bias. Recommended.
+          - "holdout": Split off calibration_fraction of data and calibrate on
+            held-out residuals. Use when you want explicit temporal holdout
+            (e.g., time-series with calibration_fraction > 0).
+          - "train": Calibrate on in-sample residuals. NOT recommended for
+            flexible models — causes systematic variance shrinkage.
+          - "none": No calibration.
+    calibration_fraction:
+        Fraction of data to hold out when calibration_method="holdout".
+        Ignored for other calibration methods.
     time_col:
-        Optional name of datetime-like column to use for time ordering/splitting.
+        Optional name of a datetime-like column in X to use for time ordering/splitting.
+        If None, uses pandas time index if present.
     """
 
     def __init__(
@@ -66,17 +84,19 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
         *,
         mean_params: Optional[Dict[str, Any]] = None,
         var_params: Optional[Dict[str, Any]] = None,
-        n_iterations: int = 1,
+        n_iterations: int = 2,
         n_oof_folds: int = 5,
         oof_splitter: Optional[Any] = None,
         oof_random_state: int = 42,
         variance_mode: str = "auto",  # "auto" | "gamma" | "log"
-        oof_residuals_reuse: bool = False,
-        calibrate: bool = True,
-        calibration_fraction: float = 0.0,
+        oof_residuals_reuse: bool = True,
+        calibration_method: str = "oof",  # "none" | "holdout" | "oof" | "train"
+        calibration_fraction: float = 0.2,
         calibration_random_state: int = 123,
         time_col: Optional[str] = None,
         eps: float = 1e-12,
+        # Deprecated parameters — will be removed in 0.3.0
+        calibrate: Optional[bool] = None,
     ):
         self.mean_params = mean_params
         self.var_params = var_params
@@ -86,12 +106,33 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
         self.oof_random_state = int(oof_random_state)
         self.variance_mode = str(variance_mode)
         self.oof_residuals_reuse = bool(oof_residuals_reuse)
-        self.calibrate = bool(calibrate)
         self.calibration_fraction = float(calibration_fraction)
         self.calibration_random_state = int(calibration_random_state)
         self.time_col = time_col
         self.eps = float(eps)
 
+        # Handle deprecated `calibrate` parameter
+        if calibrate is not None:
+            warnings.warn(
+                "The `calibrate` parameter is deprecated and will be removed in v0.3.0. "
+                "Use `calibration_method` instead: "
+                "calibrate=False -> calibration_method='none', "
+                "calibrate=True -> calibration_method='oof' (recommended) or 'holdout'.",
+                FutureWarning,
+                stacklevel=2,
+            )
+            if not calibrate:
+                calibration_method = "none"
+            elif calibration_method == "oof":
+                # User passed calibrate=True without specifying calibration_method;
+                # map to legacy behavior: holdout if fraction > 0, else train
+                if self.calibration_fraction > 0.0:
+                    calibration_method = "holdout"
+                else:
+                    calibration_method = "train"
+
+        self.calibration_method = str(calibration_method)
+
     def fit(
         self,
         X: ArrayLike,
@@ -114,11 +155,24 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
 
         eps_eff = max(self.eps, 1e-12 * max(float(np.var(y_all)), float(np.finfo(float).tiny)))
 
+        cal_method = self.calibration_method.lower().strip()
+        if cal_method not in {"none", "holdout", "oof", "train"}:
+            raise ValueError(
+                f"calibration_method must be one of: 'none', 'holdout', 'oof', 'train'. Got {cal_method!r}."
+            )
+
+        if cal_method == "train":
+            warnings.warn(
+                "calibration_method='train' calibrates on in-sample residuals, which causes "
+                "systematic variance shrinkage with flexible models. Use 'oof' or 'holdout' instead.",
+                UserWarning,
+                stacklevel=2,
+            )
+
         # Time handling: infer + sort for time-aware splitting
         time = infer_time(X, time_col=self.time_col)
         Xs, ys, ws, gs, order = time_sort(X, y_all, w_all, None if g_all is None else np.asarray(g_all), time)
 
-        # If we sorted, reorder time values so time-based operations stay aligned.
         if order is not None and time.values is not None:
             time = TimeInfo(kind=time.kind, values=np.asarray(time.values)[order], name=time.name)
 
@@ -141,8 +195,18 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
             "verbose": -1,
         }
 
-        # Calibration split (optional)
-        if self.calibrate and X_cal is None and y_cal is None and self.calibration_fraction > 0.0:
+        # Calibration holdout split (only for "holdout" method)
+        X_hold, y_hold, w_hold = None, None, None
+
+        if X_cal is not None and y_cal is not None:
+            # Explicit calibration data always takes priority
+            X_tr, y_tr, w_tr, g_tr = Xs, ys, ws, gs
+            X_hold = X_cal
+            y_hold = np.asarray(y_cal, dtype=float).reshape(-1)
+            w_hold = None if sample_weight_cal is None else np.asarray(sample_weight_cal, dtype=float).reshape(-1)
+            cal_method = "holdout"  # explicit cal data overrides
+            cal_strategy = "explicit"
+        elif cal_method == "holdout" and self.calibration_fraction > 0.0:
             X_tr, X_hold, y_tr, y_hold, w_tr, w_hold, g_tr, g_hold, cal_strategy = calibration_split(
                 Xs,
                 ys,
@@ -154,15 +218,11 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
             )
         else:
             X_tr, y_tr, w_tr, g_tr = Xs, ys, ws, gs
-            g_hold = None
-            X_hold, y_hold, w_hold = X_cal, y_cal, sample_weight_cal
-            cal_strategy = "explicit" if (X_cal is not None and y_cal is not None) else "none"
+            cal_strategy = cal_method  # "oof", "train", or "none"
 
         g_tr = None if g_tr is None else np.asarray(g_tr)
 
         # Splitter for OOF residuals
-        # Splitter for OOF residuals.
-        # Priority: explicit splitter > groups > time-aware > shuffled KFold
         if self.oof_splitter is not None:
             splitter_obj = self.oof_splitter
         elif g_tr is not None:
@@ -191,7 +251,6 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
 
         chosen_mode: Optional[str] = None
         variance_tr: Optional[np.ndarray] = None
-
         cached_res2: Optional[np.ndarray] = None
 
         for it in range(self.n_iterations):
@@ -250,7 +309,10 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
                     if requested_mode == "gamma":
                         raise
                     chosen_mode = "log"
-                    self.variance_model_info_ = VarianceModelInfo(mode="log", objective="regression", details=f"gamma_failed: {type(e).__name__}")
+                    self.variance_model_info_ = VarianceModelInfo(
+                        mode="log", objective="regression",
+                        details=f"gamma_failed: {type(e).__name__}",
+                    )
 
             if chosen_mode == "log":
                 log_params = dict(base_var_params)
@@ -269,29 +331,54 @@ class TwoStageHeteroscedasticLightGBM(HeteroscedasticRegressor):
         self.eps_ = eps_eff
         self.calibration_strategy_ = cal_strategy
 
+        # ---- Helper to get var predictions ----
+        def _predict_var(X_in: ArrayLike) -> np.ndarray:
+            if self.variance_mode_ == "gamma":
+                return np.clip(self.var_model_.predict(X_in), eps_eff, np.inf)
+            else:
+                return np.clip(np.exp(self.var_model_.predict(X_in)), eps_eff, np.inf)
+
         # ---- Calibration ----
         cal = VarianceCalibration(scale=1.0, source="none")
-        if self.calibrate:
-            if X_hold is not None and y_hold is not None:
-                y_hold_ = np.asarray(y_hold, dtype=float).reshape(-1)
-                mu_hold = self.mean_model_.predict(X_hold)
 
-                if self.variance_mode_ == "gamma":
-                    var_hold_raw = np.clip(self.var_model_.predict(X_hold), eps_eff, np.inf)
-                else:
-                    var_hold_raw = np.clip(np.exp(self.var_model_.predict(X_hold)), eps_eff, np.inf)
+        if cal_method == "holdout" and X_hold is not None and y_hold is not None:
+            y_hold_ = np.asarray(y_hold, dtype=float).reshape(-1)
+            mu_hold = self.mean_model_.predict(X_hold)
+            var_hold_raw = _predict_var(X_hold)
+            w_hold_ = None if w_hold is None else np.asarray(w_hold, dtype=float).reshape(-1)
+            cal = fit_variance_scale(
+                y_hold_, mu_hold, var_hold_raw,
+                sample_weight=w_hold_, eps=eps_eff, source="holdout",
+            )
 
-                w_hold_ = None if w_hold is None else np.asarray(w_hold, dtype=float).reshape(-1)
-                cal = fit_variance_scale(y_hold_, mu_hold, var_hold_raw, sample_weight=w_hold_, eps=eps_eff, source="holdout")
-            else:
-                mu_tr_final = self.mean_model_.predict(X_tr)
+        elif cal_method == "oof":
+            # OOF mean predictions — avoids in-sample bias, no data loss
+            def mean_factory_cal() -> Any:
+                return lgb.LGBMRegressor(**mean_params)
 
-                if self.variance_mode_ == "gamma":
-                    var_tr_raw = np.clip(self.var_model_.predict(X_tr), eps_eff, np.inf)
-                else:
-                    var_tr_raw = np.clip(np.exp(self.var_model_.predict(X_tr)), eps_eff, np.inf)
+            mu_oof = oof_mean_predictions(
+                X_tr,
+                y_tr,
+                model_factory=mean_factory_cal,
+                n_splits=self.n_oof_folds,
+                sample_weight=w_mean,
+                splitter=splitter_obj,
+                groups=g_tr,
+                random_state=self.oof_random_state,
+            )
+            var_tr_cal = _predict_var(X_tr)
+            cal = fit_variance_scale(
+                y_tr, mu_oof, var_tr_cal,
+                sample_weight=w_tr, eps=eps_eff, source="oof",
+            )
 
-                cal = fit_variance_scale(y_tr, mu_tr_final, var_tr_raw, sample_weight=w_tr, eps=eps_eff, source="train")
+        elif cal_method == "train":
+            mu_tr_final = self.mean_model_.predict(X_tr)
+            var_tr_raw = _predict_var(X_tr)
+            cal = fit_variance_scale(
+                y_tr, mu_tr_final, var_tr_raw,
+                sample_weight=w_tr, eps=eps_eff, source="train",
+            )
 
         self.calibration_ = cal
         return self
diff --git a/hetero_nll/oof.py b/hetero_nll/oof.py
index 0c3f2af..634d51a 100644
--- a/hetero_nll/oof.py
+++ b/hetero_nll/oof.py
@@ -103,3 +103,49 @@ def oof_squared_residuals(
 
     res2 = (y_ - mu_oof) ** 2
     return np.maximum(res2, eps)
+
+
+def oof_mean_predictions(
+    X: ArrayLike,
+    y: np.ndarray,
+    *,
+    model_factory: Callable[[], Any],
+    n_splits: int = 5,
+    sample_weight: Optional[np.ndarray] = None,
+    splitter: Optional[Any] = None,
+    groups: Optional[np.ndarray] = None,
+    random_state: int = 42,
+) -> np.ndarray:
+    """Compute out-of-fold mean predictions (for OOF calibration).
+
+    Returns mu_oof: array of shape (n,) where each entry is the mean
+    prediction from a model trained on all other folds.
+    """
+    y_ = _as_numpy_1d(y)
+    w_all = None if sample_weight is None else _as_numpy_1d(sample_weight)
+    g_all = None if groups is None else np.asarray(groups)
+
+    splitter_obj = choose_oof_splitter(
+        X,
+        n_splits=n_splits,
+        random_state=random_state,
+        splitter=splitter,
+        groups=None if g_all is None else _as_numpy_1d(g_all),
+    )
+
+    mu_oof = np.empty(len(y_), dtype=float)
+
+    try:
+        split_iter = splitter_obj.split(X, y_, groups=g_all)
+    except TypeError:
+        split_iter = splitter_obj.split(X, y_)
+
+    for tr_idx, va_idx in split_iter:
+        model = model_factory()
+        fit_kwargs: Dict[str, Any] = {}
+        if w_all is not None:
+            fit_kwargs["sample_weight"] = w_all[tr_idx]
+        model.fit(_slice_rows(X, tr_idx), y_[tr_idx], **fit_kwargs)
+        mu_oof[va_idx] = model.predict(_slice_rows(X, va_idx))
+
+    return mu_oof
diff --git a/hetero_nll/types.py b/hetero_nll/types.py
index a1c528d..3f72b6c 100644
--- a/hetero_nll/types.py
+++ b/hetero_nll/types.py
@@ -19,4 +19,4 @@ class VarianceCalibration:
     """Multiplicative variance calibration: var_cal = scale * var_raw."""
 
     scale: float = 1.0
-    source: str = "none"  # "holdout" | "train" | "none"
+    source: str = "none"  # "holdout" | "oof" | "train" | "none"
diff --git a/tests/test_lightgbm_smoke.py b/tests/test_lightgbm_smoke.py
index 3481be9..bf87aac 100644
--- a/tests/test_lightgbm_smoke.py
+++ b/tests/test_lightgbm_smoke.py
@@ -1,26 +1,34 @@
 import numpy as np
+import warnings
 import pytest
 
 pytest.importorskip("lightgbm")
 
 import pandas as pd
 from hetero_nll import TwoStageHeteroscedasticLightGBM
+from hetero_nll.metrics import gaussian_nll
 
 
-def test_lightgbm_fit_predict_smoke():
-    rng = np.random.default_rng(0)
-    n = 500
+def _make_data(n=500, seed=0):
+    rng = np.random.default_rng(seed)
     X = pd.DataFrame({
         "x1": rng.normal(size=n),
         "x2": rng.normal(size=n),
     })
     true_var = np.exp(0.3 + 0.7 * X["x1"].values)
     y = (2 * X["x1"] - X["x2"]).values + rng.normal(scale=np.sqrt(true_var))
+    return X, y, true_var
+
+
+def test_lightgbm_fit_predict_smoke():
+    X, y, _ = _make_data()
+    n = len(y)
 
     m = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1,
         n_oof_folds=3,
         variance_mode="auto",
-        calibrate=False,
+        calibration_method="none",
     )
     m.fit(X, y)
     pred = m.predict_dist(X)
@@ -28,3 +36,125 @@ def test_lightgbm_fit_predict_smoke():
     assert pred.mu.shape == (n,)
     assert pred.var.shape == (n,)
     assert np.all(pred.var > 0)
+
+
+def test_calibration_method_oof():
+    """OOF calibration should produce scale near 1.0 for 1-iter."""
+    X, y, _ = _make_data(n=1000)
+
+    m = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1,
+        n_oof_folds=5,
+        calibration_method="oof",
+    )
+    m.fit(X, y)
+
+    assert m.calibration_.source == "oof"
+    # OOF cal at 1 iter should be very close to 1.0
+    assert 0.8 < m.calibration_.scale < 1.2
+
+
+def test_calibration_method_holdout():
+    X, y, _ = _make_data(n=1000)
+
+    m = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1,
+        n_oof_folds=5,
+        calibration_method="holdout",
+        calibration_fraction=0.2,
+    )
+    m.fit(X, y)
+
+    assert m.calibration_.source == "holdout"
+    assert m.calibration_.scale > 0
+
+
+def test_calibration_method_train_warns():
+    X, y, _ = _make_data()
+
+    with warnings.catch_warnings(record=True) as w:
+        warnings.simplefilter("always")
+        m = TwoStageHeteroscedasticLightGBM(
+            n_iterations=1,
+            n_oof_folds=3,
+            calibration_method="train",
+        )
+        m.fit(X, y)
+
+    assert any("systematic variance shrinkage" in str(warning.message) for warning in w)
+    assert m.calibration_.source == "train"
+    # Train cal with flexible model should produce scale < 1
+    assert m.calibration_.scale < 0.8
+
+
+def test_calibration_method_none():
+    X, y, _ = _make_data()
+
+    m = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1,
+        n_oof_folds=3,
+        calibration_method="none",
+    )
+    m.fit(X, y)
+
+    assert m.calibration_.source == "none"
+    assert m.calibration_.scale == 1.0
+
+
+def test_calibration_method_invalid_raises():
+    with pytest.raises(ValueError, match="calibration_method must be"):
+        m = TwoStageHeteroscedasticLightGBM(calibration_method="bad")
+        m.fit(pd.DataFrame({"x": [1, 2, 3]}), np.array([1.0, 2.0, 3.0]))
+
+
+def test_deprecated_calibrate_param_warns():
+    X, y, _ = _make_data()
+
+    with warnings.catch_warnings(record=True) as w:
+        warnings.simplefilter("always")
+        m = TwoStageHeteroscedasticLightGBM(
+            n_oof_folds=3,
+            calibrate=False,
+        )
+
+    assert any("calibrate" in str(warning.message) and "deprecated" in str(warning.message) for warning in w)
+    assert m.calibration_method == "none"
+
+
+def test_two_iter_oof_cal_improves_nll():
+    """2 iterations with OOF cal should be at least as good as 1 iter no cal."""
+    X, y, _ = _make_data(n=2000, seed=42)
+
+    from sklearn.model_selection import train_test_split
+    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)
+
+    m1 = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1, n_oof_folds=5, calibration_method="none",
+    )
+    m1.fit(X_tr, y_tr)
+    nll1 = m1.nll(X_te, y_te)
+
+    m2 = TwoStageHeteroscedasticLightGBM(
+        n_iterations=2, n_oof_folds=5, calibration_method="oof",
+    )
+    m2.fit(X_tr, y_tr)
+    nll2 = m2.nll(X_te, y_te)
+
+    # 2 iter OOF cal should not be significantly worse
+    assert nll2 < nll1 + 0.1
+
+
+def test_explicit_cal_data_overrides():
+    """Passing X_cal/y_cal should use holdout calibration regardless of calibration_method."""
+    X, y, _ = _make_data(n=1000)
+
+    from sklearn.model_selection import train_test_split
+    X_tr, X_cal, y_tr, y_cal = train_test_split(X, y, test_size=0.2, random_state=0)
+
+    m = TwoStageHeteroscedasticLightGBM(
+        n_iterations=1, n_oof_folds=3, calibration_method="none",
+    )
+    m.fit(X_tr, y_tr, X_cal=X_cal, y_cal=y_cal)
+
+    assert m.calibration_.source == "holdout"
+    assert m.calibration_.scale > 0
